<!DOCTYPE html>
<html lang="es">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Retrato Interactivo</title>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/p5.js/1.9.0/p5.min.js"></script>
  <script src="https://unpkg.com/ml5@latest/dist/ml5.min.js"></script>
</head>

<body style="margin:0; overflow:hidden; background:#000;">
<script>
let videoEl;
let faceapi;
let detections = [];
let modeloListo = false;
let camaraLista = false; // <--- 1. Variable para saber si la cÃ¡mara iniciÃ³

function setup() {
  const w = windowWidth < 700 ? windowWidth : 640;
  const h = windowHeight < 500 ? windowHeight : 480;
  createCanvas(w, h);

  // Crear elemento de video HTML oculto
  videoEl = createCapture({
    video: { facingMode: "user", width: w, height: h },
    audio: false
  }, () => {
    console.log("ðŸŽ¥ CÃ¡mara lista");
    camaraLista = true; // <--- 2. Actualizamos la variable cuando la cÃ¡mara estÃ¡ lista
  });

  videoEl.size(w, h);
  videoEl.hide(); // No mostrar el <video> por defecto

  // Inicializar faceApi
  const options = {
    withLandmarks: true,
    withExpressions: false,
    withDescriptors: false
  };

  faceapi = ml5.faceApi(videoEl.elt, options, modelReady);

  textAlign(CENTER);
  textSize(20);
  fill(255);
}

function modelReady() {
  console.log("âœ… Modelo cargado correctamente");
  modeloListo = true;
  // <--- 3. Pasamos el video (videoEl.elt) para que sepa quÃ© detectar
  faceapi.detect(videoEl.elt, gotResults);
}

function gotResults(err, result) {
  if (err) {
    console.error(err);
    return;
  }
  detections = result;
  // <--- 4. Pasamos el video (videoEl.elt) en cada ciclo de detecciÃ³n
  faceapi.detect(videoEl.elt, gotResults);
}

function draw() {
  background(0);

  // <--- 5. Usamos nuestra variable 'camaraLista' para la verificaciÃ³n
  if (!camaraLista) {
    text("ðŸŽ¥ Iniciando cÃ¡mara...", width / 2, height / 2);
    return;
  }

  if (!modeloListo) {
    text("ðŸ§  Cargando modelo de rostro...", width / 2, height / 2);
    return;
  }

  // Dibujar video en canvas como espejo
  push();
  translate(width, 0);
  scale(-1, 1);
  image(videoEl, 0, 0, width, height);
  pop();

  // Dibujar puntos faciales
  if (detections.length > 0) {
    const puntos = detections[0].landmarks.positions;
    noStroke();
    fill(255, 100, 150, 160);
    for (let p of puntos) {
      // Ajustamos 'p.x' por el efecto espejo
      ellipse(width - p.x, p.y, 8, 8);
    }
  } else {
    fill(255);
    text("Mira hacia la cÃ¡mara ðŸ‘€", width / 2, height / 2);
  }
}

function windowResized() {
  resizeCanvas(windowWidth < 700 ? windowWidth : 640, windowHeight < 500 ? windowHeight : 480);
}
</script>
</body>
</html>
